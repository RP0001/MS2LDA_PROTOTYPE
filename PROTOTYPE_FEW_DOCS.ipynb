{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDIA_ROOT is C:\\Users\\rpetr\\OneDrive\\Desktop\\DISS_CODE\\ms2ldaviz\\ms2ldaviz\\media\n"
     ]
    }
   ],
   "source": [
    "# all the relevant imports are done here\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys\n",
    "basedir = 'C:\\\\Users\\\\rpetr\\\\OneDrive\\\\Desktop\\\\DISS_CODE\\\\ms2ldaviz\\\\ms2ldaviz'\n",
    "sys.path.append(basedir)\n",
    "import django\n",
    "import json\n",
    "django.setup()\n",
    "from basicviz.models import Experiment, Alpha, Mass2MotifInstance, FeatureInstance, Feature, Document, Mass2Motif, DocumentMass2Motif, FeatureMass2MotifInstance\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import csv\n",
    "from scipy.special import polygamma as pg\n",
    "from scipy.special import psi as psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Choose an experiment. In this case it is experiment 190. It has 500 topics, 27923 words and 2132 unique docs. These were tested against the database using appropriate queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id=190 \n",
    "experiment = Experiment.objects.get(id=experiment_id)\n",
    "min_prob_beta = 1e-3\n",
    "SMALL_NUMBER = 1e-100\n",
    "eta = 0.1 #needed for beta m-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORPUS (features for 1 document in experiment 190)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First we get all features in the database for our experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all features in the database relevant for our experiment. \n",
    "features = Feature.objects.filter(experiment_id=experiment)\n",
    "experiment_words = []\n",
    "for f in features:\n",
    "     if f.id not in experiment_words: \n",
    "        experiment_words.append(f.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique words lists all the features as {feature_id:incremental_id} word value pairs. \n",
    "unique_words = {}\n",
    "index = 0\n",
    "for word in experiment_words:\n",
    "    if word not in unique_words.keys():\n",
    "        unique_words.update({word:index})\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Then we get a random document for our experiment from the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use a single document for our experiment. Modify here if more documents are needed. \n",
    "experiment_docs=[269323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique documents is the dictionary -> doc: id \n",
    "unique_docs = {}\n",
    "index = 0 \n",
    "for doc in experiment_docs: \n",
    "    unique_docs.update({doc:index})\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the features only for the specific documents and create the corpus dictionary {DOC:{WORD:COUNT}}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features for all documents chosen. The output columns are doc_id, word_id and intensity.\n",
    "feature_instances = FeatureInstance.objects.filter(document_id__in=unique_docs.keys(), feature_id__in=unique_words.keys())\n",
    "doc_word_data = []\n",
    "for f in feature_instances:\n",
    "    doc_word_data.append([unique_docs[int(f.document_id)], unique_words[int(f.feature_id)], f.intensity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a csv for the corpus in order to create a dictionary made up of {document_id:{word_id:intensity}}. \n",
    "# Intensity in this case is an integer (count).\n",
    "doc_word_array = np.array(doc_word_data)\n",
    "np.savetxt(\"corpus_data.csv\", doc_word_array, delimiter=\",\", fmt=\"%s\")\n",
    "np.save(\"corpus_data\",doc_word_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CREATE THE CORPUS - a dictionary where key is document id and value is a dict of the count of words\n",
    "corpus_dict = {}\n",
    "with open(\"corpus_data.csv\", 'r') as data_file:\n",
    "    data = csv.DictReader(data_file, delimiter=\",\")\n",
    "    for row in data:\n",
    "        item = corpus_dict.get(row[\"doc_id\"], dict())\n",
    "        item[row[\"word_id\"]] = int(row[\"count\"])\n",
    "        corpus_dict[row[\"doc_id\"]] = item\n",
    "#Get the corpus dict whenever this is necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIQUE TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 500 unique topics for the experiment. \n",
    "mi = Mass2Motif.objects.filter(experiment=experiment)\n",
    "unique_topics = {}\n",
    "index=0\n",
    "for m in mi: \n",
    "    unique_topics.update({m.id:index})\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALPHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the alphas from the database (it is a vector)\n",
    "al = Alpha.objects.filter(mass2motif__experiment=experiment).order_by('mass2motif')\n",
    "alphas = {}\n",
    "for a in al:\n",
    "    alphas.update({unique_topics[a.mass2motif_id]: a.value})\n",
    "n_motif = len(alphas)\n",
    "alpha_vec = np.zeros(n_motif)\n",
    "for pos,val in alphas.items():\n",
    "    alpha_vec[pos] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vector = alpha_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to text if necessary \n",
    "# np.savetxt(\"alpha.csv\", alpha_vector, delimiter=\",\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get beta from the database (it is a topic * words 2d matrix - each cell is a probability)\n",
    "beta_pre_pivot = []\n",
    "mi = Mass2MotifInstance.objects.filter(mass2motif__experiment=experiment)\n",
    "for m in mi:\n",
    "    beta_pre_pivot.append([unique_topics[m.mass2motif_id], unique_words[m.feature_id], m.probability]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some topics may have 0 words - these have been reincluded \n",
    "# Creating array from the beta data and subsequently creating a pivot (matrix)\n",
    "output_arr_beta = np.array(beta_pre_pivot)\n",
    "K = len(unique_topics)\n",
    "W = len(unique_words)\n",
    "pivot_table = np.zeros((K, W)).astype('float')\n",
    "i = 0\n",
    "max = len(beta_pre_pivot)\n",
    "while i<max:\n",
    "    pivot_table[int(output_arr_beta[i][0]),int(output_arr_beta[i][1])]=output_arr_beta[i][2]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to get beta csv. \n",
    "# np.savetxt(\"beta.csv\", pivot_table, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the beta pivot table matrix. \n",
    "pivot_table_normalised = pivot_table\n",
    "i = 0\n",
    "while i<K: \n",
    "    row = pivot_table_normalised[i, :]\n",
    "    adjusted_row = row + SMALL_NUMBER\n",
    "    normalised_row = adjusted_row / np.sum(adjusted_row)\n",
    "    np.sum(normalised_row)\n",
    "    pivot_table_normalised[i, :] = normalised_row\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to output a csv for the beta matrix if needed. \n",
    "# np.savetxt(\"beta_matrix.csv\", pivot_table_normalised, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for visualisation if necessary \n",
    "# my_dpi=150\n",
    "# plt.figure(figsize=(2000/my_dpi, 2000/my_dpi), dpi=my_dpi)\n",
    "# plt.imshow(pivot_table_normalised, aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET ORIGINAL THETA(NORM GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the original theta from the database for subsequent comparison \n",
    "# remember theta is just normalised gamma and represents a docs * topics matrix \n",
    "theta = DocumentMass2Motif.objects.filter(document_id__in=experiment_docs)\n",
    "output_data_theta = []\n",
    "for t in theta:\n",
    "    output_data_theta.append([unique_docs[int(t.document_id)], unique_topics[int(t.mass2motif_id)], t.probability])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 94, 0.902611552679438],\n",
       " [0, 286, 0.0340671553770332],\n",
       " [0, 200, 0.0186782260549867],\n",
       " [0, 414, 0.0109110112103501],\n",
       " [0, 499, 0.0158815907979228]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET ORIGINAL PHI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the features related to the instances\n",
    "feature_instance = FeatureInstance.objects.filter(document_id__in=experiment_docs)\n",
    "feature_instance_join = {}\n",
    "for i in feature_instance:\n",
    "    feature_instance_join.update({int(i.id):[int(i.document_id), int(unique_words[i.feature_id])]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect docs, topics and features into a list of lists\n",
    "feature_m2m_instance = FeatureMass2MotifInstance.objects.filter(mass2motif__experiment=experiment)\n",
    "phi_list = []\n",
    "for i in feature_m2m_instance:\n",
    "    if i.featureinstance_id in feature_instance_join.keys():\n",
    "        phi_list.append([feature_instance_join[int(i.featureinstance_id)][0], unique_topics[int(i.mass2motif_id)], feature_instance_join[int(i.featureinstance_id)][1],i.probability])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives the original phi, which in abstract terms is a 3D matrix -> docs * topics * words\n",
    "phi_original = []\n",
    "for line in phi_list: \n",
    "    phi_original.append([line[0],line[2],line[1],line[3]])\n",
    "phi_original_array = np.array(phi_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"phi_original_array.csv\", phi_original_array, delimiter=\",\", fmt=\"%s\")\n",
    "# np.save(\"phi_original_array\", phi_original_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-STEP (has 9 steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - E-step variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_vector is already mentioned above\n",
    "# beta_matrix is created here from pivot_table_normalised\n",
    "# K and W are from above for total unique topics, total unique words respectively \n",
    "# you need a corpus (created above)\n",
    "corpus = corpus_dict\n",
    "beta_matrix = pivot_table_normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Initialise phi matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the 3D matrix phi with zeroes\n",
    "phi_matrix={}\n",
    "for doc in corpus: \n",
    "    d = int(doc)\n",
    "    phi_matrix[d] = {}\n",
    "    for word in corpus[doc]:\n",
    "        w = int(word)\n",
    "        phi_matrix[d][w]=np.zeros(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - initialise gamma matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a gamma matrix with rows as documents and columns as topics \n",
    "# this will later be transposed in order to create the phi matrix in the steps 3-9 below\n",
    "# doc_total is the count of words per doc, and each gamma is alpha plus that\n",
    "\n",
    "gamma_matrix=np.zeros((int(len(corpus)),int(K))) #3x500 shape\n",
    "for doc in corpus:\n",
    "    doc_total=0.0\n",
    "    for word in corpus[doc]:\n",
    "        doc_total += corpus[doc][word]\n",
    "    gamma_matrix[int(doc),:] = alpha_vector + 1.0*(doc_total/K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - 9: repeat until convergence loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise phi and do Blei's loop \n",
    "test_list = []\n",
    "iterations=10000\n",
    "n_words = int(len(unique_words))\n",
    "temp_beta = np.zeros((K, n_words))\n",
    "current_gamma = np.copy(gamma_matrix)\n",
    "for i in range(iterations):   \n",
    "    prev_gamma = np.copy(current_gamma)\n",
    "    for doc in corpus:\n",
    "        d = int(doc)\n",
    "        doc_dict = corpus[doc]\n",
    "        temp_gamma = np.zeros(K) + alpha_vector\n",
    "        for word in doc_dict: #the word is actually column positioning so we do not need n^3 complexity \n",
    "            w = int(word)\n",
    "            log_phi_matrix = np.log(beta_matrix[:,w]) + psi(gamma_matrix[d,:]).T\n",
    "            log_phi_matrix = np.exp(log_phi_matrix - log_phi_matrix.max())\n",
    "            phi_matrix[d][w] = log_phi_matrix/log_phi_matrix.sum()\n",
    "            temp_gamma += phi_matrix[d][w]*corpus[doc][word]\n",
    "            temp_beta[:,w] += phi_matrix[d][w] * corpus[doc][word]\n",
    "        gamma_matrix[d,:] = temp_gamma\n",
    "        pos = np.where(gamma_matrix[d,:]<SMALL_NUMBER)[0]\n",
    "        gamma_matrix[d,pos] = SMALL_NUMBER\n",
    "    current_gamma = np.copy(gamma_matrix)\n",
    "    gamma_diff = ((current_gamma - prev_gamma)**2).sum()\n",
    "#     beta_matrix = temp_beta\n",
    "    test_list.append([i, gamma_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the output list of the above e-step \n",
    "# test_list[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an array output if necessary \n",
    "gamma_diff_array = np.array(test_list)\n",
    "np.savetxt(\"gamma_diff_array.csv\", gamma_diff_array, delimiter=\",\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARISON OF GAMMA & PHI (original vs calculated csv exports) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma comparison / actually Theta comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "0.902611552679\n",
      "286\n",
      "0.034067155377\n",
      "200\n",
      "0.018678226055\n",
      "414\n",
      "0.0109110112104\n",
      "499\n",
      "0.0158815907979\n"
     ]
    }
   ],
   "source": [
    "# output_data_theta is the original data we work with, which is an 3 column matrix (doc_id, topic_id, probability)\n",
    "# we aim to transform output_data_theta into a normalised vector \n",
    "# note that this implementation only works for a single document \n",
    "gamma_vector_original = np.zeros(K) \n",
    "for line in range(len(output_data_theta)):\n",
    "    pos = int(output_data_theta[line][1])\n",
    "    prob = output_data_theta[line][2]\n",
    "    gamma_vector_original[pos] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 9.19016422e-001, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.90177008e-002, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 3.46863223e-002, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.11093177e-002, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.01817489e-100,\n",
       "       1.01817489e-100, 1.01817489e-100, 1.01817489e-100, 1.61702370e-002])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalise the original gamma vector\n",
    "gamma_vector_original += SMALL_NUMBER\n",
    "gamma_vector_original /= np.sum(gamma_vector_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.52218166e-104, 1.35758892e-104, 2.88619028e-003, 1.35758892e-104,\n",
       "       1.80748212e-104, 1.82316927e-104, 1.67820705e-104, 1.85193650e-104,\n",
       "       1.16846463e-003, 1.75294255e-104, 1.52218532e-104, 1.90186923e-104,\n",
       "       1.87796647e-104, 1.59791990e-104, 1.59791990e-104, 1.35758892e-104,\n",
       "       6.01713523e-004, 1.79071341e-104, 1.59792001e-104, 1.64366423e-104,\n",
       "       2.05711079e-104, 1.89015425e-104, 1.52267901e-104, 1.89015425e-104,\n",
       "       1.35758892e-104, 1.59791991e-104, 1.70665061e-104, 1.52219276e-104,\n",
       "       6.41507950e-004, 2.01764163e-104, 1.77263751e-104, 1.64366423e-104,\n",
       "       1.20858896e-003, 1.46562872e-003, 1.59792003e-104, 1.52218735e-104,\n",
       "       1.75294255e-104, 1.67820705e-104, 1.67820705e-104, 6.88272798e-004,\n",
       "       1.59791990e-104, 1.93461427e-104, 1.79071341e-104, 1.73117760e-104,\n",
       "       1.67820705e-104, 3.06470401e-004, 1.70665061e-104, 1.86524977e-104,\n",
       "       1.94484463e-104, 1.77263751e-104, 1.35758892e-104, 1.77263751e-104,\n",
       "       1.75294255e-104, 1.35758892e-104, 2.26336762e-104, 1.91315851e-104,\n",
       "       4.24619108e-003, 1.52218297e-104, 8.44382242e-004, 6.80265785e-004,\n",
       "       1.64366423e-104, 1.64397095e-104, 1.64366423e-104, 1.73117760e-104,\n",
       "       1.35758892e-104, 1.59791990e-104, 3.60036791e-003, 1.75294255e-104,\n",
       "       1.83794395e-104, 1.64366423e-104, 1.35758892e-104, 1.77263751e-104,\n",
       "       2.21597679e-104, 1.64366423e-104, 1.64366423e-104, 1.35758892e-104,\n",
       "       1.85193650e-104, 1.59792003e-104, 1.82316927e-104, 1.77263751e-104,\n",
       "       1.82316927e-104, 1.59792004e-104, 1.35758892e-104, 1.75294255e-104,\n",
       "       1.79071341e-104, 5.03262558e-003, 1.80748212e-104, 2.04950755e-104,\n",
       "       6.88217379e-004, 1.59791993e-104, 1.77263751e-104, 1.79071341e-104,\n",
       "       2.17621709e-104, 1.67820705e-104, 6.76022395e-001, 1.70665061e-104,\n",
       "       1.52218859e-104, 1.77263751e-104, 1.52218158e-104, 1.82316927e-104,\n",
       "       1.35758892e-104, 1.70665061e-104, 1.64366423e-104, 1.80748212e-104,\n",
       "       1.70665061e-104, 1.59791991e-104, 1.52219548e-104, 1.64366423e-104,\n",
       "       1.35758892e-104, 1.64366423e-104, 1.35758892e-104, 1.59792005e-104,\n",
       "       2.19928349e-104, 5.44840975e-003, 1.64366424e-104, 1.52218175e-104,\n",
       "       1.82316927e-104, 1.39433182e-003, 1.52218183e-104, 5.43273548e-003,\n",
       "       1.59791991e-104, 1.59791992e-104, 5.55425862e-004, 1.83794395e-104,\n",
       "       1.79071341e-104, 1.70665061e-104, 1.73117760e-104, 1.64366423e-104,\n",
       "       1.37118041e-003, 1.73117760e-104, 1.68750695e-002, 3.91836711e-003,\n",
       "       1.73117760e-104, 1.59791990e-104, 2.16430422e-104, 1.59791992e-104,\n",
       "       1.91315851e-104, 1.77263751e-104, 1.35758892e-104, 1.59791990e-104,\n",
       "       1.79071341e-104, 2.90364317e-004, 1.52280491e-104, 1.52218245e-104,\n",
       "       6.38344787e-004, 1.59791990e-104, 1.64366423e-104, 2.01764163e-104,\n",
       "       2.41666022e-003, 1.59791990e-104, 2.36884132e-003, 4.06032238e-003,\n",
       "       9.79111938e-003, 1.35758892e-104, 1.95477898e-104, 1.67820705e-104,\n",
       "       1.86524977e-104, 2.07915925e-104, 1.64366423e-104, 4.27486350e-002,\n",
       "       1.52220104e-104, 1.35758892e-104, 1.59791991e-104, 1.59791995e-104,\n",
       "       1.80748212e-104, 1.67820705e-104, 2.61117521e-004, 1.52218165e-104,\n",
       "       1.77263751e-104, 1.59791990e-104, 1.64366423e-104, 1.53582757e-003,\n",
       "       1.35758892e-104, 1.99197109e-104, 1.52218174e-104, 2.02540419e-003,\n",
       "       5.44566088e-004, 1.52218630e-104, 1.06717077e-003, 1.93461427e-104,\n",
       "       1.52218172e-104, 1.59791990e-104, 1.85193650e-104, 7.76205810e-004,\n",
       "       1.59791998e-104, 1.64366423e-104, 1.35758892e-104, 1.73117760e-104,\n",
       "       1.59791990e-104, 1.70665061e-104, 1.35758892e-104, 1.64366423e-104,\n",
       "       2.11369153e-104, 1.35758892e-104, 1.67820705e-104, 1.85193650e-104,\n",
       "       1.64366423e-104, 1.35758892e-104, 1.67820705e-104, 1.70665061e-104,\n",
       "       1.81430612e-002, 1.67820705e-104, 1.77263751e-104, 1.75294255e-104,\n",
       "       1.67820705e-104, 1.75294255e-104, 2.63523520e-004, 1.64366423e-104,\n",
       "       1.64366423e-104, 1.70665061e-104, 1.35758892e-104, 7.08323444e-004,\n",
       "       1.75294255e-104, 1.91315851e-104, 1.75294255e-104, 1.82316927e-104,\n",
       "       1.35758892e-104, 1.70665061e-104, 1.35758892e-104, 1.59791990e-104,\n",
       "       1.75294255e-104, 1.70665061e-104, 1.59791991e-104, 1.70665061e-104,\n",
       "       2.42857574e-104, 2.00927016e-104, 1.85193650e-104, 2.01764163e-104,\n",
       "       1.70665061e-104, 1.67820705e-104, 3.19973782e-003, 1.79071341e-104,\n",
       "       1.52221522e-104, 1.70665061e-104, 1.79071341e-104, 1.86524977e-104,\n",
       "       1.35758892e-104, 2.33059992e-104, 1.35758892e-104, 1.67820705e-104,\n",
       "       1.75294255e-104, 1.59791991e-104, 1.70665061e-104, 1.59791991e-104,\n",
       "       1.35758892e-104, 1.86524977e-104, 1.35758892e-104, 1.35758892e-104,\n",
       "       1.64366423e-104, 1.67820705e-104, 1.64366424e-104, 1.77263751e-104,\n",
       "       3.83084458e-003, 1.79071341e-104, 1.64366423e-104, 1.67820705e-104,\n",
       "       1.35758892e-104, 2.13327328e-104, 8.42644293e-004, 1.77263751e-104,\n",
       "       1.59791990e-104, 1.67820705e-104, 1.52218277e-104, 1.75294255e-104,\n",
       "       1.90186953e-104, 1.75294255e-104, 1.80748212e-104, 1.67820705e-104,\n",
       "       1.83794395e-104, 8.21192087e-004, 1.35758892e-104, 1.35758892e-104,\n",
       "       1.52218289e-104, 1.59791990e-104, 1.70665061e-104, 2.24798407e-104,\n",
       "       6.06623937e-004, 1.87796647e-104, 1.83794395e-104, 1.35758892e-104,\n",
       "       1.80748212e-104, 2.07037333e-003, 1.52218175e-104, 1.52218648e-104,\n",
       "       1.77263751e-104, 1.64366423e-104, 4.11574396e-002, 1.77444269e-003,\n",
       "       1.35758892e-104, 1.52218181e-104, 1.67820705e-104, 1.59791996e-104,\n",
       "       1.59793484e-104, 1.59791990e-104, 1.52218226e-104, 1.59794138e-104,\n",
       "       1.64366423e-104, 1.75294255e-104, 1.86524977e-104, 1.73609628e-003,\n",
       "       1.67820705e-104, 1.59791991e-104, 1.52225601e-104, 1.52220498e-104,\n",
       "       1.72502353e-003, 1.35758892e-104, 1.35758892e-104, 2.18093710e-003,\n",
       "       1.26726012e-003, 1.37196487e-003, 1.64366423e-104, 1.82316927e-104,\n",
       "       1.35758892e-104, 1.59791990e-104, 1.75294255e-104, 1.35758892e-104,\n",
       "       8.59150377e-004, 1.64366423e-104, 1.83794395e-104, 1.73117760e-104,\n",
       "       1.70665061e-104, 1.99197109e-104, 1.70665061e-104, 1.35758892e-104,\n",
       "       1.75736043e-003, 1.59792402e-104, 1.67820705e-104, 1.75294255e-104,\n",
       "       3.52616625e-003, 1.75294255e-104, 1.35758892e-104, 1.35758892e-104,\n",
       "       1.35758892e-104, 1.67820705e-104, 3.15376928e-003, 8.41099576e-004,\n",
       "       1.67820705e-104, 1.86524977e-104, 1.75294255e-104, 1.45289442e-004,\n",
       "       1.70665061e-104, 1.59792006e-104, 1.79071341e-104, 1.59791991e-104,\n",
       "       1.67820705e-104, 1.67820705e-104, 1.95477898e-104, 1.64366423e-104,\n",
       "       1.59791990e-104, 1.85193650e-104, 1.52218202e-104, 1.87843821e-002,\n",
       "       1.70665061e-104, 1.35758892e-104, 1.52218227e-104, 1.35758892e-104,\n",
       "       1.67820705e-104, 1.59791992e-104, 1.73117760e-104, 1.75294255e-104,\n",
       "       1.52219012e-104, 1.35758892e-104, 1.82316927e-104, 1.35758892e-104,\n",
       "       1.79071341e-104, 1.52226806e-104, 2.04176665e-104, 1.59791990e-104,\n",
       "       1.80748212e-104, 1.80748212e-104, 1.35758892e-104, 2.85291050e-104,\n",
       "       2.91871032e-104, 1.90186923e-104, 2.05711079e-104, 1.70665061e-104,\n",
       "       1.79071341e-104, 1.83794395e-104, 1.94484463e-104, 1.67820705e-104,\n",
       "       1.52218476e-104, 1.07064780e-003, 1.90186923e-104, 1.35758892e-104,\n",
       "       1.35758892e-104, 1.64366423e-104, 1.75294255e-104, 1.59791990e-104,\n",
       "       1.67820705e-104, 1.87796647e-104, 1.52225425e-104, 1.89015425e-104,\n",
       "       1.70665061e-104, 1.77263751e-104, 1.64366423e-104, 1.75294255e-104,\n",
       "       1.89015425e-104, 1.73117760e-104, 1.52218205e-104, 1.64366423e-104,\n",
       "       1.64366423e-104, 1.86524977e-104, 2.44828685e-104, 1.35758892e-104,\n",
       "       1.77263751e-104, 1.70665061e-104, 1.87796647e-104, 1.59791990e-104,\n",
       "       1.82316927e-104, 1.79071341e-104, 4.16519993e-004, 2.42857574e-104,\n",
       "       2.05711079e-104, 2.30694046e-003, 1.05043493e-002, 2.03388078e-104,\n",
       "       2.64274836e-104, 2.34862556e-104, 2.00927016e-104, 1.75294255e-104,\n",
       "       1.52218288e-104, 2.07193066e-104, 7.08859495e-003, 1.67820705e-104,\n",
       "       1.52218197e-104, 1.98301924e-104, 2.39050763e-002, 2.03388078e-104,\n",
       "       2.64274836e-104, 2.49371990e-104, 2.49739631e-104, 3.57115602e-003,\n",
       "       5.84834168e-003, 2.42457340e-104, 1.73117760e-104, 9.22345768e-004,\n",
       "       1.52218184e-104, 1.94484463e-104, 1.51576339e-003, 2.02584200e-104,\n",
       "       7.66792098e-004, 1.35758892e-104, 2.04176665e-104, 1.77263751e-104,\n",
       "       2.09328042e-104, 1.67820705e-104, 1.64366423e-104, 1.87796647e-104,\n",
       "       1.51364937e-003, 1.67820705e-104, 1.35758892e-104, 1.35758892e-104,\n",
       "       1.64367315e-104, 1.94484463e-104, 1.35758892e-104, 4.20699587e-003,\n",
       "       1.59791997e-104, 2.21046679e-104, 2.04950755e-104, 1.79071341e-104,\n",
       "       1.67820705e-104, 1.35758892e-104, 1.52218264e-104, 1.67820705e-104,\n",
       "       1.70665061e-104, 1.67820705e-104, 2.70064608e-104, 2.42857574e-104,\n",
       "       2.47885170e-104, 2.11369153e-104, 2.18207564e-104, 1.49213299e-003,\n",
       "       2.07193066e-104, 2.55762834e-104, 1.95477898e-104, 3.24963253e-004,\n",
       "       1.77263751e-104, 2.10698493e-104, 2.01764163e-104, 2.85291050e-104,\n",
       "       2.19360699e-104, 2.28330206e-104, 1.73117760e-104, 2.03388078e-104,\n",
       "       1.59791990e-104, 1.96443994e-104, 2.06458309e-104, 1.80748212e-104,\n",
       "       1.73117760e-104, 1.87796647e-104, 1.85193650e-104, 1.85193650e-104,\n",
       "       1.85193650e-104, 1.52922170e-003, 1.75011364e-003, 1.98301924e-104,\n",
       "       2.07193066e-104, 2.18207564e-104, 2.44046132e-104, 1.68983080e-002])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalise calculated gamma vector\n",
    "gamma_vector_calculated = np.zeros(K) \n",
    "gamma_vector_calculated = np.copy(gamma_matrix[0])\n",
    "gamma_vector_calculated /= np.sum(gamma_vector_calculated)\n",
    "gamma_vector_calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for comparison - to be automatised later \n",
    "# np.savetxt(\"compare_gamma1.csv\", gamma_vector_original, delimiter=\",\", fmt=\"%s\")\n",
    "# np.savetxt(\"compare_gamma2.csv\", gamma_vector_calculated, delimiter=\",\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array form of the original phi to csv.\n",
    "# np.savetxt(\"phi_original_array.csv\", phi_original_array, delimiter=\",\", fmt=\"%s\")\n",
    "# np.save(\"phi_original_array\", phi_original_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bring Phi Matrix calculated in e-step to list form here. \n",
    "phi_calculated = []\n",
    "for line in phi_list: \n",
    "    line_doc = unique_docs[line[0]]\n",
    "    line_topic = int(line[2])\n",
    "    line_word = int(line[1])\n",
    "    line_prob = phi_matrix[line_doc][line_topic][line_word]\n",
    "    phi_calculated.append([line_doc, line_topic, line_word, line_prob])\n",
    "phi_calculated_array = np.array(phi_calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array form of the new phi to csv.\n",
    "# np.savetxt(\"phi_calculated_array.csv\", phi_calculated_array, delimiter=\",\", fmt=\"%s\")          \n",
    "# np.save(\"phi_calculated_array\", phi_calculated_array)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOMATED COMPARISON GAMMA/PHI (to be completed) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
